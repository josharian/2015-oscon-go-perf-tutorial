Go Performance Tutorial

Josh Bleecher Snyder
Braintree/PayPal
josharian@gmail.com
@offbymany

# introduce myself, contributions to Go, etc.


* Plan

- Introduction and philosophy
- Tools: Benchmarks, profiles

- Break

- Habits and techniques: string/[]byte, memory, concurrency
- Advanced tools and techniques

- Break

- Other kinds of optimization
- Wrap-up and stump the chump


* Introduction and philosophy

# lots to say, so there will be interludes throughout
# but here are the key points


* Write simple, clear code

- Usually the fastest anyway

.link https://codereview.appspot.com/131840043

- Easy to see optimization opportunities
- Compiler and runtime optimized for normal code
- Take it easy on abstraction (reflection, interfaces)

"All problems in computer science can be solved by another level of indirection, except of course for the problem of too many indirections." - David Wheeler

* Write good tests and use version control

Enables experimentation.

"If you're not going to get the right answer, I don't see the point. I can make things very fast if they don't have to be correct." - Russ Cox


* Develop good habits

"Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%." - Donald Knuth

# we'll discuss good habits as we go
# get the basics right: caching, lazy initialization, better algorithms


* Know thy tools, at all levels

- Can you cheat? Does it matter?
- Algorithms
- Language
- Benchmarking and profiling
- Machine and OS: Disk vs network vs memory

"People who are more than casually interested in computers should have at least some idea of what the underlying hardware is like. Otherwise the programs they write will be pretty weird." - Donald Knuth


* The easiest wins around

- Use the most recent release of Go!
- Use the standard library.
- Use more hardware.


* Benchmarking


* Hello, benchmarks

Demo: package fib

# how to write, run, and interpret a benchmark
# adaptive benchtime
# -bench=regexp, -run=NONE, -benchtime
# full power of language at disposal
# careful about which benchmarks you write
# beware microbenchmarks

* Tour of testing.B and 'go test' flags

Demo: word length count

# b.SetBytes
# -benchmem, b.ReportAllocs
# b.Errorf, b.Logf, -v
# danger: these skew benchmarking! demo with ReportAllocs
# and wow, reflect.DeepEqual is expensive!
# b.ResetTimer, b.StopTimer, b.StartTimer
# show Go 1.4 vs Go tip (1.5)


* Comparing benchmarks

- benchcmp

	go get -u golang.org/x/tools/cmd/benchcmp

- benchviz

	go get -u github.com/ajstarks/svgo/benchviz

- benchstat

	go get -u rsc.io/benchstat

# hope for more in 1.6


* Benchmarking concurrent code

Demo: ngram

# -cpu, b.PB, b.RunParallel, b.SetParallelism
# how to set up global state and goroutine-local state
# what it does under the hood
# tip: Use rand.Zipf to simulate real load


* Profiling

* Hello, profiling

- Where have all the cycles gone?
- Support built into the runtime
- `go`tool`pprof`, graphviz
- OS X sadness


# helps you understand you program's performance via instrumentation
# different kinds of profiling: cpu, memory, block profiling, tracing
# cpu works by sampling, with support from the OS; OS X needs a patch
# other kinds of profiling work using instrumentation in the runtime
# cpu is efficient, can run on live production server, memory less so
# different kinds of profiling interfere with each other

# NetBSD also has (had?) broken profiling


* CPU profiling

Demo: fib

# show basic usage: -cpuprofile, -outputdir
# saves binary
# don't run any tests, target individual benchmarks
# -lines -pdf -nodecount=10 -focus=fib 
# be careful about hiding things!
# mention:
#  can set CPU profiling rate


* Memory profiling

Demo: ascii

# start with load
# discover syscalls
# remove syscalls

# discover malloc
# add ReportAllocs
# do mem profiling
# need -l
# need -alloc_objects, discuss alternatives
# discuss -memprofilerate

# move on to encode
# discover malloc
# add ReportAllocs
# mem profiling
# need -l? nope.
# need -runtime flag to pprof
# aha! string concatenation. Use a bytes.Buffer. Will discuss more later. common problem.

# syscall: look at syscalls. malloc: look at allocation. mutex/futex/channel-y things? look at blocking. We'll get to that.


* Profiling gotchas

- Don't run multiple profilers at once.
- Don't run tests when profiling.
- If the output doesn't make sense, poke around or ask for help.

# pprof has a crappy UI. Live with it. :(


* Block profiling

Demo: ngram

# easy demo: -blockprofile=
# discuss -blockprofilerate, -memprofilerate
# there is a way to change cpu profile rate in runtime package but too fast can't happen (OS support, expense of walking the stack) and the default is pretty good
# discuss ok/expected blocking: time.Ticker, sync.WaitGroup


* Other kinds of profiling

In package `runtime/pprof`:

- `goroutine`: helpful for finding sources of leaking goroutines
- `threadcreate` helpful for debugging runaway thread creation (usually syscalls or cgo)

# TODO: Expand?

Basic memory stats available in package `runtime`: `ReadMemStats`

.link https://golang.org/pkg/runtime/#MemStats


* Whole program profiling

Set up first thing in `func`main`.

Use `runtime` and `runtime/pprof`...but it is a pain.

# Mention gotchas like flushing and closing the files,
# calling runtime.GC before exit, etc.

Dave Cheney made a nice helper package:

	go get -u github.com/pkg/profile

.link https://godoc.org/github.com/pkg/profile


* Monitoring live servers

Cheap enough to do in production!

And easy, using `net/http/pprof`.

	import _ "net/http/pprof"

Use pprof to view CPU:

	go tool pprof -pdf http://localhost:4001/debug/pprof/profile > o.pdf && open o.pdf

Heap:

	go tool pprof http://localhost:4001/debug/pprof/heap

Goroutines:

	go tool pprof http://localhost:4001/debug/pprof/goroutine

See `net/http/pprof` docs.


* Monitoring live servers

Demo: present

	go tool pprof -pdf http://localhost:4001/debug/pprof/goroutine > o.pdf && open o.pdf

Oh goodness!

.link https://github.com/golang/go/issues/11507


* Protecting the net/http/pprof endpoints

`net/http/pprof` registers endpoints with `http.DefaultServeMux`.

So don't use `http.DefaultServeMux`.

	serveMux := http.NewServeMux()
	// use serveMux to serve your regular website

	pprofMux := http.NewServeMux()
	pprofMux.HandleFunc("/debug/pprof/", pprof.Index)
	pprofMux.HandleFunc("/debug/pprof/cmdline", pprof.Cmdline)
	pprofMux.HandleFunc("/debug/pprof/profile", pprof.Profile)
	pprofMux.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
	// use pprofMux to serve the pprof handles

Or use a single non-default `ServeMux` but insert http handler middleware.


* Execution tracing

- New as of Go 1.5! Google for "Go execution tracer" to see the design doc.
- A few rough edges still.
- Incredibly detailed and powerful, with all the good and bad that that brings.


* Execution tracing

Demo: ngram

# go test -bench=. -trace=trace.out -benchtime=50ms
# go tool trace ngram.test trace.out

# before and after
# observe blocked goroutines before, interleaved goroutines after

# play with it and explore. I still am.


* Break

# switch to present14!


* Techniques and habits


* string and []byte


* string and []byte

Common source of performance problems.
Easy to learn good habits.
Helps to know what's happening under the hood.


* Under the hood

*string*

- basic type
- interpreted as UTF-8
- _immutable_

*[]byte*

- just another slice type
- no particular interpretation
- _mutable_

.play stringbytes/mutable.go /func set/,/^}/


* Correct conversions are expensive

Above all, the compiler and runtime must be correct.
Speed is a bonus.

In the general case, converting between string and []byte requires an alloc and a copy.

.play stringbytes/convert.go /func Benchmark/,/^}/


* Shrink and grow

*string*

- slicing is very cheap and safe
- concatenation is expensive (alloc + copy x 2)

*[]byte*

- slicing is very cheap but not always safe
- append is sometimes expensive (sometimes alloc, always copy x 1, sometimes copy x 2)


* Good habits

- Live in just one world (modulo code clarity and correctness).
- Convert as late as possible.
- Pay attention to concatenation, particularly in loops.

# that's why we have parallel strings and bytes packages
# now specific techniques/habits
# these are not rules. clarity trumps, but these are generally equally clear.
# these might only matter in loops. but get in the habit of writing performant code.


* bytes.Buffer

Use a bytes.Buffer to build strings.

.play stringbytes/buf.go /func Benchmark/,/^$/

# important change for c2go compiler performance!


* APIs

Use dedicated APIs:

- bytes and strings packages
- "io.Writer".Write vs io.WriteString
- "bufio.Scanner".Bytes vs "bufio.Scanner".Text
- "bytes.Buffer".Bytes vs "bytes.Buffer".String

Related: Implement WriteString for your io.Writers:

	func WriteString(s string) (n int, err error)


* Avoid building strings

If the set of choices is small, pick a string rather than building it.
(Or use stringer: golang.org/x/tools/cmd/stringer.)

# TODO: Example code with benchmark


* Order of operations

Convert last (usually).

For example, slice after converting.

.play stringbytes/slice.go /Repeat/,/func _/

If you're slicing multiple times, there are trade-offs: Multiple small alloc+copy vs one large monolithic chunk of memory.


* Easy on the Sprintf

Use concatenation and strconv instead of fmt.Sprintf for simple things.

.play stringbytes/strconv.go /func Benchmark/,/^$/


* API design

Design your APIs to allow reduced garbage.

- Provide []byte and string variants.
- Use io.Reader and io.Writer instead of buffers.
- BYO buffer.


* Techniques

- Reuse buffers.
- Take advantage of compiler optimizations.
- Intern strings.

# distinguish habits from techniques:
# habits are things you should usually do;
# techniques are things to use when profiling says you need to optimize.

# compiler optimization overlaps with "delay conversion"


* Reuse buffers

.play stringbytes/reuse.go /pool/,/func _/

# can also reuse with a local free list. do whatever is appropriate.
# note that sync.Pool's efficiency is implementation-dependent.


* Convert last

Pop quiz: How many allocs/op in this benchmark?

.play stringbytes/convertnoescape.go /Benchmark/,/^}/

# answer: it varies!
# Go 1.4: 1
# Go 1.5: 0
# Go 1.5, with a longer byte slice: 1!
# explain escape analysis, compiler optimizations


* Compiler magic

Conversion optimizations in Go 1.5 include:

- map keys
- range expressions
- concatenation
- comparisons

Convert as late as possible to enable them to work.
(Future work may change that.)

More are possible. Those that work well on normal code may eventually be implemented.


* Map keys

The map key optimization is particularly interesting.

.play stringbytes/mapkey.go /Repeat/,/func _/


* Interning strings

.play stringbytes/intern.go /interned/,/func _/


* Caution

Be careful with interning!

- Advanced technique. Use with caution and only when necessary.
- Depends on compiler version.
- *Manual*memory*management!* Ewwwwww.
- Not thread safe. (But see github.com/josharian/intern for a hack.)


* Optimizing memory usage


* What is allocation?

Making a place to put stuff.

- You can't avoid all allocation. That's ok!
- Why it matters: allocation, zeroing/copying, GC, limited resource, impact on caches.
- Number of allocations vs size of allocation.

# Talking about allocs because they have are usually
# a significant contributor to program performance.


* What allocates?

Lots of things, but it varies by compiler.
In practice, there are no strict rules.

Common sources of allocations are:

- Data growth (append, concatenation, map assignment, stacks)
- new, make, and &
- string/[]byte conversion
- Interface conversions
- Closures

Develop good habits, profile, and benchmark.


* Escape analysis

- Heap vs stack
- Subtle, interacts with growable stacks and GC
- Stack pressure vs heap
- `-gcflags=-m`

# Mostly, just know that it exists.
# TODO: Ask folks to file issues?


* Good habits

- Avoid unnecessary data growth.
- Avoid unnecessary string/[]byte conversions.
- Design APIs that allow re-use.
- Use values where you can.
- Avoid gratuitous boxing, reflection, and indirection.

# Stream instead of buffering.
# Example of values: 0, 1, 2 instead of *bool.
# Example of when not to use values: large arrays, particularly ranging over them.


* Unnecessary data growth

Buffer:

	buf, err := ioutil.ReadAll(r)
	// check err
	var x T
	err = json.Unmarshal(buf, &x)
	// check err

Stream:

	dec := json.NewDecoder(r)
	var x T
	err := dec.Decode(&x)
	// check err


* Unnecessary/deep recursion

Stacks take memory too. Stack growth is an alloc+copy+process.

(Most data growth is alloc+copy.)


* API design

Use io.Reader and io.Writer.

Also, io.Reader is a fine example itself!

	type Reader interface {
	    Read(p []byte) (n int, err error)
	}

It is hard to anticipate your users' needs. Give them the tools to be efficient if they need it.


* Use values

Value:

	type OptBool uint8

	const (
		Unset = OptBool(iota)
		SetFalse
		SetTrue
	)

Pointer:

	type OptBool *bool


But take care with large values.

	var a [10000]int{}
	for _, i := range a {
	}
	fmt.Println(a)

# not just copy cost, also impact on cache usage, etc.


* Go easy on the abstraction

- Reflect allocates heavily.
- Most interface conversions allocate.
- Creating closures usually allocates.

# abstraction is ok, just not needless abstraction


* Techniques

- Provide initial capacity estimates for data structures.
- Trade off allocation size and number of allocations.
- Reuse objects. Maintain a free list or use sync.Pool.
- Steal ideas from the standard library.


* Initial capacity estimates


Delayed alloc, but multiple allocs:

	var s []int
	for i := 0; i < 100; i++ {
		s = append(s, i)
	}


Exactly one alloc, up front:

	s := make([]int, 0, 100)
	for i := 0; i < 100; i++ {
		s = append(s, i)
	}

# Disagreement over whether this is habit vs technique.
# TODO: Insert a benchmark here demoing.


* Pre-allocate backing array

    type Buffer struct {
    	buf       []byte
    	off       int
    	runeBytes [utf8.UTFMax]byte
    	bootstrap [64]byte
    	lastRead  readOp
    }

runeBytes avoids allocation during WriteRune:

	utf8.EncodeRune(b.runeBytes[0:], r)

bootstrap avoids allocation for small buffers:

	b.buf = b.bootstrap[0:]

# trading off alloc size vs number of allocs
# this about impact on cache


* Reuse objects

Local re-use is better:

	buf := make([]byte, 1024)
	for {
		n, err := r.Read(buf)
		// use err, n, buf
		// look out: buf's contents will be overwritten in the next Read call
	}


Sometimes there's no context (type or scope) to allow re-use. Enter sync.Pool:

	for {
		buf := pool.Get().([]byte)
		// use buf
		// optional: clear buf for safety
		for i := range buf {
			buf[i] = 0
		}
		pool.Put(buf)
	}

# TODO: benchmark


* Struct layout

Go guarantees struct field alignment.

	type Efficient struct {
		a interface{}
		b *int
		c []int
		d uint16
		e bool
		f uint8
	}

	type Inefficient struct {
		e bool
		a interface{}
		f uint8
		b *int
		d uint16
		c []int
	}

	var e Efficient
	var i Inefficient
	fmt.Println(unsafe.Sizeof(e), unsafe.Sizeof(i)) // 28 36

# TODO: Turn into play program
# Discuss cache impact
# Discuss GC impact of having pointers first
# Mention gc compiler and Nodes
# Mention runtime alloc size classes
# golang.org/cl/2179
# golang.org/issue/10014
# Won't happen automatically:
#	No Go compiler should probably ever reorder struct fields.
#	That seems like it is trying to solve a 1970s problem,
#	namely packing structs to use as little space as possible.
#	The 2010s problem is to put related fields near each other to reduce cache misses,
#	and (unlike the 1970s problem) there is no obvious way
#	for the compiler to pick an optimal solution.
#	A compiler that takes that control away from the programmer
#	is going to be that much less useful,
#	and people will find better compilers. - Russ Cox


* Optimizing concurrent programs


* Optimizing concurrent programs

Concurrency correctness is hard, even with Go.


* Habits

- Use mutexes instead of channels for simple shared state.
- Minimize critical sections.
- Don't leak goroutines.
- Gate access to shared resources, particularly the file system.

# not much else to say about mutexes vs channels
# chann


* Mutexes and channels

Mutexes are good for mutual exclusion, like simple shared state. They are fast and simple in such cases.

Channels are for everything else: Flow control, communication, coordination, select.

# Honest truth: This is actually about readability and code clarity.
# It just happens to also coincide with good performance advice.


* Minimize critical sections

Separate work that requires shared state from work that does not.
Only hold the lock when you really need it. Refactor as needed.

Before:

	func (t *T) Update() {
		t.Lock()
		defer t.Unlock()
		// expensive work that can be done independently
		// update shared state
	}

After

	func (t *T) Update() {
		// expensive work that can be done independently
		t.Lock()
		defer t.Unlock()
		// update shared state
	}


* Don't leak goroutines

When you start a new goroutine, pause to ask when it will/how it will complete.

	func doh(c chan int) {
		go func() {
			for i := range c {
				// use i
			}
		}()
		// who closes c? who calls doh?
	}

Goroutines are so cheap you might not notice leaks quickly.

Profile or manually inspect the result of a SIGQUIT.


* Gate access to shared resources

It's easy to thrash the filesystem, make lots of threads, and create churn in the scheduler. It's also easy to prevent.

	type gate chan bool

	func (g gate) enter() { g <- true }
	func (g gate) leave() { <-g }

	type gatefs struct {
		fs vfs.FileSystem
		gate
	}

	func (fs gatefs) Open(p string) (vfs.ReadSeekCloser, error) {
		fs.enter()
		defer fs.leave()
		// ...
		return gatef{file, fs.gate}, nil
	}

	var fsgate = make(gate, 8)

# not needed for the network
# needed for cgo


* Techniques

- sync.RWMutex is only sometimes better than sync.Mutex.
- Use buffered channels.
- Partition shared data structures.
- Batch work to amortize cost of lock acquisition.
- Use sync/atomic.
- Avoid false sharing by padding data structures.


* sync.RWMutex vs sync.Mutex

sync.RWMutex does strictly more work than sync.Mutex and has more complicated semantics.

# Discuss writer starvation

sync.RWMutext can help a lot, but it can also hurt. Profile and/or benchmark.

# don't just automatically use RWMutex


* Use buffered channels

Buffered and unbuffered channels have different semantics and synchronization guarantees.

Buffered channels are much cheaper, if both semantics work for you.

# discuss queueing theory: buffer size only provides a buffer
# buffer sizes come at a memory cost


* Partition shared data structures

Before:

	type Counter struct {
		mu sync.Mutex
		m  map[string]int
	}

After:

	const shards = 16

	type Counter struct {
		mu [shards]sync.Mutex
		m  [shards]map[string]int
	}

Can reduce contention.

Adds cost of hashing, increases data structure size, and depends on distribution of data. Measure with real world data. `rand.Zipf` can be helpful for benchmarks.


* Batch work

	// consumer
	var sum int
	for i := range c {
		sum += i
	}

	// producer before
	for !done {
		sum := count(stuff)
		c <- sum
	}

	// producer after
	for !done {
		sum := 0
		for i := 0; i < 16; i++ {
			sum += count(stuff)
		}
		c <- sum
	}

Can dramatically reduce contention, but not always applicable. Can introduce delays due to batching.

# example: goroutine goids per-thread
# example: testing.PB
# example: hand out worklist items a slice at a time


* atomic.Value

	var (
		configmu    sync.Mutex    // protects configvalue
		configvalue *atomic.Value // value of map[string]string
	)

	func config() map[string]string {
		return configvalue.Load().(map[string]string)
	}

	func set(key, val string) {
		configmu.Lock()
		defer configmu.Unlock()
		old := config()
		m := make(map[string]string, len(old)+1)
		for k, v := old {
			m[oldk] = oldv
		}
		m[k] = v
		configvalue.Store(m)
	}

For frequently read but infrequently written data structures. Requires copy-on-write and writer synchronization (or a single writer). Danger of logical races.


* atomic int and pointer operations

	var count uint32

	func inc() {
		atomic.AddUint32(&count, 1)
	}

	func get() uint32 {
		return atomic.LoadUint32(&count)
	}

Cheapest form of synchronization available in Go. Great caution required; very easy to misuse in subtle ways!

Mostly helpful for cheap, scalable counters.

If you use atomic.* with a value anywhere, you must use it everywhere!

Special care required when using 64 bit integer sizes on 32 bit platforms. (Read: Don't do it.)


* Avoid false sharing

Usually solvable by rearrangement or padding.

	type T [1024]Padded

	type Padded struct {
		mu sync.Mutex
		x  *X
		_  [128]byte
	}

Diagnose first; the medicine is bitter.

